# -*- coding: utf-8 -*-
"""ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1soMAYljXoJOotz8uE1mzYeKsbRT_Gsg7
"""

import pandas as pd
from sklearn.model_selection import KFold

!pip install -U scikit-learn

from google.colab import files
uploaded = files.upload()

#Data Cleaning remocing all unimportnat columns
bikes = pd.read_csv('hour.csv')
bike = bikes.iloc[:, [2,4,5,6,7,8,11,13,16]]
bike

#A correlation matrix to see if there is any obvious correlations
correlationMatrix = bikes.corr()
print(correlationMatrix)

import seaborn as sn
import matplotlib.pyplot as plt

#Crearting a heat map to understand the correlation
sn.heatmap(correlationMatrix, annot=True)
plt.show()

#Creating the boolean high rent value shich classifies anything over the mean bikes rented an hour as high rent
bikes['high rent'] = (bikes['cnt'] >= bikes['cnt'].mean())*1

#Create X
X = bikes.iloc[:, 2:14]

#Create our y for using a numeric prediction 
Y_num = bikes['cnt']

#Create a boolean y for classification
Y_bool = bikes['high rent']

from sklearn.model_selection import train_test_split

# with y bool

xb_train, xb_test, yb_train, yb_test = train_test_split(X, Y_bool, test_size = 0.2)

# with y num

x_train, x_test, yn_train, yn_test = train_test_split(X, Y_num, test_size = 0.2)

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression
import numpy as np
from sklearn import metrics

x_train.describe()

#Using Random Forest to predict numeric values
rfr = RandomForestRegressor(n_estimators = 20)
rfr.fit(x_train, yn_train)
pred = rfr.predict(x_test)

pred

#Finding error in the prediction
print('Mean Absolute Error:', metrics.mean_absolute_error(yn_test, pred))
print('Mean Squared Error:', metrics.mean_squared_error(yn_test, pred))
print('Mean Absolute Percentage Error:', np.mean(np.abs((yn_test - pred) / yn_test)) * 100)
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(yn_test, pred)))

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()

#Using Random Forest to classify
rfc = RandomForestClassifier(n_estimators = 20)
rfc_model = rfc.fit(xb_train, yb_train)
yb_pred = rfc.predict(xb_test)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
#Finding error information
print(confusion_matrix(yb_test,yb_pred))
print(classification_report(yb_test,yb_pred))
print(accuracy_score(yb_test, yb_pred))

"""# Naive Bayes"""

from sklearn.datasets import load_iris
from sklearn.naive_bayes import GaussianNB

# Commented out IPython magic to ensure Python compatibility.
#Using Naive Bayes to estimate predict classification
gnb = GaussianNB()
y_pred = gnb.fit(xb_train, yb_train).predict(xb_test)
print("Number of mislabeled points out of a total %d points : %d"
#        % (xb_test.shape[0], (yb_test != y_pred).sum()))
#Finding Error information
print(classification_report(yb_test, y_pred))
print(accuracy_score(yb_test, y_pred))

"""#Neural Network"""

from sklearn.neural_network import MLPClassifier
nn = MLPClassifier(solver='lbfgs', alpha=1e-5, max_iter=25000,
                     hidden_layer_sizes=(5, 2), random_state=1)
nn.fit(xb_train, yb_train)

#Using Neural Network to predict classification
yb_pred = nn.predict(x_test)
#Measuring Error
print(confusion_matrix(yb_test,yb_pred))
print(classification_report(yb_test,yb_pred))
print(accuracy_score(yb_test, yb_pred))

"""#Log Regression"""

from sklearn.linear_model import LogisticRegression
#Using Log Regression to predict classification
clf = LogisticRegression(random_state=0).fit(xb_train, yb_train)
#Measuring Error
y_pred = clf.predict(xb_test)
print(confusion_matrix(yb_test,y_pred))
print(classification_report(yb_test,y_pred))
print(accuracy_score(yb_test, y_pred))

"""# Ridge Regression"""

from sklearn.datasets import make_regression
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
#Using Ridge regression to predict numeric estimations
rr = Ridge(alpha=0.01)
rr.fit(x_train, yn_train)
pred_rr_train = rr.predict(x_train)
print(np.sqrt(mean_squared_error(yn_train, pred_rr_train)))
print(r2_score(yn_train, pred_rr_train))
#Measuring Error
pred_rr_test = rr.predict(x_test)
print(np.sqrt(mean_squared_error(yn_test, pred_rr_test)))
print(r2_score(yn_test, pred_rr_test))